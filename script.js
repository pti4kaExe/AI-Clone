// Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð¸ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð² Ð½Ð°Ñ‡Ð°Ð»Ð¾ script.js
let isRecording = false;
let mediaRecorder;
let audioChunks = [];
let recognition; // Ð´Ð»Ñ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ Ñ€ÐµÑ‡Ð¸

// Ð­Ð»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ
const voiceBtn = document.getElementById('voiceBtn');
const voiceStatus = document.getElementById('voiceStatus');

// Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ Ñ€ÐµÑ‡Ð¸ (Web Speech API)
function initSpeechRecognition() {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        recognition = new SpeechRecognition();
        recognition.lang = 'ru-RU';
        recognition.continuous = false;
        recognition.interimResults = false;
        
        recognition.onresult = function(event) {
            const transcript = event.results[0][0].transcript;
            userAnswerEl.value = transcript;
            voiceStatus.textContent = 'âœ… Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð¾: ' + transcript.substring(0, 50) + '...';
        };
        
        recognition.onerror = function(event) {
            console.error('Speech recognition error', event.error);
            voiceStatus.textContent = 'âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ';
        };
        
        recognition.onend = function() {
            isRecording = false;
            voiceBtn.textContent = 'ðŸŽ¤ Ð“Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÑŒ';
            voiceBtn.style.background = '#4299e1';
        };
    } else {
        console.warn('Speech recognition not supported');
        voiceStatus.textContent = 'âš ï¸ Ð‘Ñ€Ð°ÑƒÐ·ÐµÑ€ Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑ‡Ð¸';
    }
}

// Ð—Ð°Ð¿Ð¸ÑÑŒ Ð³Ð¾Ð»Ð¾ÑÐ°
async function startVoiceRecording() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
                channelCount: 1,
                sampleRate: 16000,
                sampleSize: 16
            } 
        });
        
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];
        
        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                audioChunks.push(event.data);
            }
        };
        
        mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            // Ð—Ð´ÐµÑÑŒ Ð¼Ð¾Ð¶Ð½Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð°ÑƒÐ´Ð¸Ð¾ Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€ Ð´Ð»Ñ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ
            // ÐÐ¾ Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ñ‚Ñ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ðµ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ
            if (recognition) {
                recognition.start();
            }
        };
        
        mediaRecorder.start();
        isRecording = true;
        voiceBtn.textContent = 'â¹ ÐžÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð·Ð°Ð¿Ð¸ÑÑŒ';
        voiceBtn.style.background = '#e53e3e';
        voiceStatus.textContent = 'ðŸŽ¤ Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÑŽ... Ð“Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚Ðµ!';
        
    } catch (error) {
        console.error('Error accessing microphone:', error);
        voiceStatus.textContent = 'âŒ ÐÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ñƒ';
    }
}

function stopVoiceRecording() {
    if (mediaRecorder && isRecording) {
        mediaRecorder.stop();
        isRecording = false;
        // ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð²ÑÐµ Ñ‚Ñ€ÐµÐºÐ¸ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°
        mediaRecorder.stream.getTracks().forEach(track => track.stop());
    }
}

// ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÐºÐ½Ð¾Ð¿ÐºÐ¸ Ð³Ð¾Ð»Ð¾ÑÐ°
voiceBtn.addEventListener('click', () => {
    if (!isRecording) {
        startVoiceRecording();
    } else {
        stopVoiceRecording();
    }
});
